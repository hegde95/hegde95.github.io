<!doctype html><html lang=en><head><meta name=generator content="Hugo 0.119.0"><title>Shashank's Blog</title><meta name=description content="Portfolio and personal blog of John Doe."><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="ie=edge"><link rel=stylesheet href=/application.9829f6e644fd6ee3337588785b384c2fb93c78ec013327d111962c50da6fd057.css integrity="sha256-mCn25kT9buMzdYh4WzhML7k8eOwBMyfREZYsUNpv0Fc="><link rel=icon type=image/png href=/images/site/ai_icon_hufa7d5e224a3980a85cb962d2ea605e3f_19579_42x0_resize_q75_box.jpeg><meta property="og:title" content="Shashank's Blog"><meta property="og:type" content="website"><meta property="og:description" content="Portfolio and personal blog of Shashank Hegde."><meta property="og:image" content="/images/author/shashank.png"><meta property="og:url" content="https://hegde95.github.io"><meta name=twitter:card content="summary"><meta name=twitter:title content="Shashank's Blog"><meta name=twitter:description content><script>theme=localStorage.getItem("darkmode:color-scheme")||"system",theme=="system"&&(window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches?theme="dark":theme="light"),document.documentElement.setAttribute("data-theme",theme)</script></head><body data-spy=scroll data-target=#top-navbar data-offset=100><nav class="navbar navbar-expand-xl top-navbar shadow transparent-navbar homepage" id=top-navbar><div class=container><a class=navbar-brand href=/><img src=/images/site/ai_icon_hufa7d5e224a3980a85cb962d2ea605e3f_19579_42x0_resize_q75_box.jpeg id=logo alt=Logo>
Shashank's Blog</a>
<button class="navbar-toggler navbar-dark" id=navbar-toggler type=button data-toggle=collapse data-target=#top-nav-items aria-label=menu>
<i data-feather=menu></i></button><div class="collapse navbar-collapse dynamic-navbar" id=top-nav-items><ul class="navbar-nav ml-auto"><li class=nav-item><a class=nav-link href=/#home>Home</a></li><li class=nav-item><a class=nav-link href=/#about>About</a></li><li class=nav-item><a class=nav-link href=/#experiences>Experiences</a></li><li class=nav-item><a class=nav-link href=/#publications>Select Publications</a></li><li class=nav-item><a class=nav-link href=/#projects>Projects</a></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# id=navbarDropdown role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false>More</a><div class=dropdown-menu aria-labelledby=navbarDropdown><a class=dropdown-item href=/#skills>Skills</a>
<a class=dropdown-item href=/#education>Education</a>
<a class=dropdown-item href=/#accomplishments>Accomplishments and Service</a></div></li></ul></div></div><img src=/images/site/ai_icon_hufa7d5e224a3980a85cb962d2ea605e3f_19579_42x0_resize_q75_box.jpeg class=d-none id=main-logo alt=Logo>
<img src=/images/site/ai_icon_hufa7d5e224a3980a85cb962d2ea605e3f_19579_42x0_resize_q75_box.jpeg class=d-none id=inverted-logo alt="Inverted Logo"></nav><div class="container-fluid home" id=home><style>#homePageBackgroundImageDivStyled{background-image:url(/images/site/la_hu845ee49037092faf6c3b680abbaaac73_1212570_500x0_resize_q75_box.jpg)}@media(min-width:500px) and (max-width:800px){#homePageBackgroundImageDivStyled{background-image:url(/images/site/la_hu845ee49037092faf6c3b680abbaaac73_1212570_800x0_resize_q75_box.jpg)}}@media(min-width:801px) and (max-width:1200px){#homePageBackgroundImageDivStyled{background-image:url(/images/site/la_hu845ee49037092faf6c3b680abbaaac73_1212570_1200x0_resize_q75_box.jpg)}}@media(min-width:1201px) and (max-width:1500px){#homePageBackgroundImageDivStyled{background-image:url(/images/site/la_hu845ee49037092faf6c3b680abbaaac73_1212570_1500x0_resize_q75_box.jpg)}}@media(min-width:1501px){#homePageBackgroundImageDivStyled{background-image:url(/images/site/la.jpg)}}</style><span class=on-the-fly-behavior></span><div id=homePageBackgroundImageDivStyled class="background container-fluid"></div><div class="container content text-center"><img src=/images/author/shashank_hu04224e32a4047a5cbb80ba43fc99b51f_35954_148x148_fit_q75_box.jpeg class="rounded-circle mx-auto d-block img-fluid" alt="Author Image"><h1 class=greeting>Hi, I am Shashank</h1><div class=typing-carousel><span id=ityped class=ityped></span>
<span class=ityped-cursor></span></div><ul id=typing-carousel-data><li>I'm a Researcher</li><li>I'm a Roboticist</li><li>I'm a PhD Student</li><li>I love AI</li><li>I'm a Developer</li><li>I work on open-source projects</li><li>I'm a musician</li><li>I love music</li></ul><a href=#about class=arrow-center aria-label="Read More - Shashank"><i class="arrow bounce fa fa-chevron-down"></i></a></div></div><div class="container-fluid section-holder d-flex bg-primary"><div class="container anchor p-lg-5 about-section" id=about><div class="row pt-sm-2 pt-md-4 align-self-center"><div class=col-sm-12><h3 class=p-1>Shashank Hegde</h3><h5 class=p-1>AI PhD Researcher
at <a href=https://robotics.usc.edu/resl/ title="Robotics Embedded Systems Lab." target=_blank rel=noopener>Robotics Embedded Systems Lab.</a></h5><p class="p-1 text-justify">I am a passionate AI researcher with a strong background in computer vision and robotics. I am currently pursuing my PhD in Electrical and Computer Engineering at the University of Southern California. My research interests include deep reinforcement learning, machine learning, and robotics. I am a strong believer in the power of AI to improve the quality of life of people around the world.</p><div class="text-container ml-auto"><ul class="social-link d-flex"><li><a href=mailto:kshegde6@gmail.com title=Email target=_blank rel=noopener><i class="fas fa-envelope"></i></a></li><li><a href=https://github.com/hegde95 title=Github target=_blank rel=noopener><i class="fab fa-github"></i></a></li><li><a href=https://www.linkedin.com/in/karkala-shashank-hegde/ title=LinkedIn target=_blank rel=noopener><i class="fab fa-linkedin"></i></a></li><li><a href=https://twitter.com/hegde_shashank title=Twitter target=_blank rel=noopener><i class="fab fa-twitter"></i></a></li></ul></div><a href=/files/resume.pdf title="My Resume" target=#><button class="btn btn-dark">My Resume</button></a></div><div class="col-sm-6 pt-5 pl-md-4 pl-sm-3 pt-sm-0"><div class=row></div></div></div></div></div><div class="container-fluid section-holder d-flex bg-secondary"><div class="container-fluid anchor pb-5 experiences-section"><h1 class=text-center><span id=experiences></span>Experiences</h1><div class="container timeline text-justify"><div class="row align-items-center d-flex"><div class="col-1 col-lg-2 text-center vertical-line d-inline-flex justify-content-center"><div class="circle font-weight-bold">1</div></div><div class="col-10 col-lg-8"><div class=experience-entry-heading><h5>PhD Researcher</h5><h6><a href=https://robotics.usc.edu/resl/ title="Robotic Embedded Systems Lab, University of Southern California" target=_blank rel=noopener>Robotic Embedded Systems Lab, University of Southern California</a></h6><p class=text-muted>Sept 2021 - Present,
Los Angeles, CA</p></div><p>RESL is a research lab at the University of Southern California. The lab is headed by Prof. Gaurav Sukhatme. The lab is focused on robotics and AI research.</p><h6 class=text-heading>Responsibilities:</h6><ul class=justify-content-around><li>Develop sample efficient leaning methods for quadruped hurdling tasks on SLURM clusters. Use Sample factory for distributed learning with reduced policy lag.</li><li>Experiment with audio based communication between agents for multi agent reinforcement learning.</li><li>Create high performing small Neural Networks on AWS for robotic control, to fulfill device and time latency constraints.</li></ul></div></div><div class="row horizontal-line"><div class="col-1 col-lg-2 timeline-side-div"><div class=corner></div></div><div class="col-10 col-lg-8"><hr></div><div class="col-1 col-lg-2 timeline-side-div"><div class=corner></div></div></div><div class="row align-items-center justify-content-end d-flex"><div class="col-10 col-lg-8"><div class=experience-entry-heading><h5>Data Scientist</h5><h6>SalesDNA (stealth mode Startup)</h6><p class=text-muted>May 2021 - August 2021,
Los Angeles, CA</p></div><p>This company investigates the application of AI in the field of sales</p><h6 class=text-heading>Responsibilities:</h6><ul class=justify-content-around><li>Built data pipelines for collection, cleaning and modelling. Use real time Markov modelling for a sales process.</li><li>Built model free reinforcement learning algorithms to build AI strategies on this sales simulation.</li></ul></div><div class="col-1 col-lg-2 text-center vertical-line d-inline-flex justify-content-center"><div class="circle font-weight-bold">2</div></div></div><div class="row horizontal-line"><div class="col-1 col-lg-2 timeline-side-div"><div class=corner></div></div><div class="col-10 col-lg-8"><hr></div><div class="col-1 col-lg-2 timeline-side-div"><div class=corner></div></div></div><div class="row align-items-center d-flex"><div class="col-1 col-lg-2 text-center vertical-line d-inline-flex justify-content-center"><div class="circle font-weight-bold">3</div></div><div class="col-10 col-lg-8"><div class=experience-entry-heading><h5>Reasearch Assistant</h5><h6><a href=https://viterbi-web.usc.edu/~rahuljai/Welcome.html title="Stochastic Systems & Learning Laboratory, University of Southern California" target=_blank rel=noopener>Stochastic Systems & Learning Laboratory, University of Southern California</a></h6><p class=text-muted>May 2020 - May 2021,
Los Angeles, CA</p></div><p>SSLL is a research lab at the University of Southern California. The lab is headed by Prof. Rahul Jain. The lab is focused on theoretical reinforcement learning .</p><h6 class=text-heading>Responsibilities:</h6><ul class=justify-content-around><li>Build scale-able Reinforcement Learning policies using function approximators with lesser trainable parameters.</li><li>Study and Apply state of the art Imitation Learning techniques to self driving vehicles and experiment on Hyper realistic simulations such as CARLA.</li></ul></div></div><div class="row horizontal-line"><div class="col-1 col-lg-2 timeline-side-div"><div class=corner></div></div><div class="col-10 col-lg-8"><hr></div><div class="col-1 col-lg-2 timeline-side-div"><div class=corner></div></div></div><div class="row align-items-center justify-content-end d-flex"><div class="col-10 col-lg-8"><div class=experience-entry-heading><h5>Reasearch Assistant</h5><h6><a href=https://viterbi-web.usc.edu/~rahuljai/Welcome.html title="Dynamic Robotics and Control Laboratory[, University of Southern California" target=_blank rel=noopener>Dynamic Robotics and Control Laboratory[, University of Southern California</a></h6><p class=text-muted>November 2019 - October 2020,
Los Angeles, CA</p></div><p>DRCL is a research lab at the University of Southern California. The lab is headed by Prof. Quan Nguyen. The lab is focused on robotic control.</p><h6 class=text-heading>Responsibilities:</h6><ul class=justify-content-around><li>Simulate and control a quadruped mini cheetah robot on Pybullet and Gazebo, by using stochastic control with policy gradient based agents. Test the RL controller on the actual robot after integration with ROS.</li><li>Experiment on different action spaces such as impedance control, torque control, force control, and use hybrid learning methods with model predictive control to help faster learning. Use RLLib for distributed learning.</li></ul></div><div class="col-1 col-lg-2 text-center vertical-line d-inline-flex justify-content-center"><div class="circle font-weight-bold">4</div></div></div><div class="row horizontal-line"><div class="col-1 col-lg-2 timeline-side-div"><div class=corner></div></div><div class="col-10 col-lg-8"><hr></div><div class="col-1 col-lg-2 timeline-side-div"><div class=corner></div></div></div><div class="row align-items-center d-flex"><div class="col-1 col-lg-2 text-center vertical-line d-inline-flex justify-content-center"><div class="circle font-weight-bold">5</div></div><div class="col-10 col-lg-8"><div class=experience-entry-heading><h5><a href=https://www.fidelity.com/ title="Fidelity Investments" target=_blank rel=noopener>Fidelity Investments</a></h5><p class=text-muted>June 2016 - July 2019,
Bangalore, India</p><p>Fidelity Investments is renowned financial institution that specializes in investment management, retirement planning, portfolio guidance, brokerage, benefits outsourcing, and many other financial products and services.</p></div><div class=positions><h6 class=designation>Software Engineer</h6><p class=text-muted>July 2017 - July 2019</p><ul class=justify-content-around><li>Develop applications based on Supervised Machine Learning for trade order selection and efficient execution.</li><li>Research on Reinforcement Learning and its application on portfolio construction in equity trading. A Gym simulation was built using real trading data. Google Tensorflow was used during the course of this work.</li><li>Worked with the Equity Trading team to develop and support the java and python based trading engine. Gained experience in java spring-boot, python flask, SQL, splunk, AWS and many other software developer tools.</li></ul><h6 class=designation>Software Engineer Intern</h6><p class=text-muted>June 2016 - August 2016</p><ul class=justify-content-around><li>Worked with the fixed income research team to build a complete end to end application using .NET and Excel VBA. Gained experience in the Microsoft Windows Presentation framework for building hard clients.</li></ul></div></div></div><div class="row horizontal-line"><div class="col-1 col-lg-2 timeline-side-div"><div class=corner></div></div><div class="col-10 col-lg-8"><hr></div><div class="col-1 col-lg-2 timeline-side-div"><div class=corner></div></div></div><div class="row align-items-center justify-content-end d-flex"><div class="col-10 col-lg-8"><div class=experience-entry-heading><h5>Research Intern</h5><h6>Mangalore University.</h6><p class=text-muted>May 2014 - June 2015,
Mangalore, India</p></div><p>Laboratory of Applied Biology, Kuppers Biotech Unit.</p><h6 class=text-heading>Responsibilities:</h6><ul class=justify-content-around><li>Predicting growth trend of algae after studying the effect of light on enhanced algal bio-fuel production. These predictions were done using Linear regression on the collected time series data.</li></ul></div><div class="col-1 col-lg-2 text-center vertical-line d-inline-flex justify-content-center"><div class="circle font-weight-bold">6</div></div></div></div></div></div><div class="container-fluid section-holder d-flex bg-primary"><div class="container-fluid anchor pb-5 publications-section" id=publications><h1 class=text-center><span id=publications></span>Select Publications</h1><div class="container ml-auto text-center"><div class="btn-group flex-wrap" role=pub-group id=publication-filter-buttons><button type=button class="btn btn-dark pub-filtr-control" data-filter=pub-all>
All</button>
<button type=button class="btn btn-dark pub-filtr-control" data-filter="pub-reinforcement learning">
Reinfocement Learning</button>
<button type=button class="btn btn-dark pub-filtr-control" data-filter="pub-signal processing">
Signal Processing</button>
<button type=button class="btn btn-dark pub-filtr-control" data-filter=pub-diffusion>
Diffusion</button>
<button type=button class="btn btn-dark pub-filtr-control" data-filter=pub-robotics>
Robotics</button></div></div><div class="container filtr-publications"><div class=row id=publication-card-holder><div class="col-12 p-2 pub-filtr-item" data-category='pub-all,pub-reinforcement learning,pub-robotics'><div class="card mt-3"><div class=card-header><h5 class="card-title mb-0">HyperPPO- A scalable method for finding small policies for robotic control</h5><div class=sub-title><span><a href>(Submitted to ICRA24)</a></span>
<span class=ml-2></span></div><div class=authors><span class=mr-2><a href=https://hegde95.github.io/>Shashank Hegde</a></span>
<span class=mr-2><a href=https://zhehui-huang.github.io/>Zhehui Huang</a></span>
<span class=mr-2><a href=https://robotics.usc.edu/resl/people/1/>Dr. Gaurav Sukhatme</a></span></div></div><div class=card-body><p>We propose HyperPPO, an on-policy reinforcement learning algorithm that utilizes graph hypernetworks to estimate the weights of multiple neural architectures simultaneously. Our method estimates weights for networks that are much smaller than those in common-use networks yet encode highly performant policies. We obtain multiple trained policies at the same time while maintaining sample efficiency and provide the user the choice of picking a network architecture that satisfies their computational constraints.</p></div><div class=card-footer><div class=tags><span class="btn badge btn-info ml-1 p-2">reinforcement learning</span>
<span class="btn badge btn-info ml-1 p-2">robotics</span></div><div class=details-btn><a class="btn btn-outline-info ml-1 pl-2 mb-2" href=https://sites.google.com/usc.edu/hyperppo target=_blank rel=noopener role=button>Details</a></div></div></div></div><div class="col-12 p-2 pub-filtr-item" data-category=pub-all,pub-diffusion,pub-robotics><div class="card mt-3"><div class=card-header><h5 class="card-title mb-0">Generating Behaviorally Diverse Policies with Latent Diffusion Models</h5><div class=sub-title><span><a href>(Accepted at NeurIPS23)</a></span>
<span class=ml-2></span></div><div class=authors><span class=mr-2><a href=https://hegde95.github.io/>Shashank Hegde</a></span>
<span class=mr-2><a href=https://sumeetbatra.github.io/>Sumeet Batra</a></span>
<span class=mr-2><a href=https://robotics.usc.edu/resl/people/1/>Dr. Gaurav Sukhatme</a></span></div></div><div class=card-body><p>In this work, we propose using diffusion models to distill a dataset of policies into a single generative model over policy parameters. We show that our method achievesa compression ratio of 13x while recovering 98% of the original rewards and 89% of the original coverage. Furthermore, the conditioning mechanism of diffusion models allows for flexibly selecting and sequencing behaviors using language.</p></div><div class=card-footer><div class=tags><span class="btn badge btn-info ml-1 p-2">diffusion</span>
<span class="btn badge btn-info ml-1 p-2">robotics</span></div><div class=details-btn><a class="btn btn-outline-info ml-1 pl-2 mb-2" href=https://sites.google.com/view/policydiffusion/home target=_blank rel=noopener role=button>Details</a></div></div></div></div><div class="col-12 p-2 pub-filtr-item" data-category='pub-all,pub-reinforcement learning,pub-robotics'><div class="card mt-3"><div class=card-header><h5 class="card-title mb-0">Efficiently Learning Small Policies for Locomotion and Manipulation</h5><div class=sub-title><span><a href=https://www.icra2023.org/>(Presented at ICRA23)</a></span>
<span class=ml-2>29 May 2023</span></div><div class=authors><span class=mr-2><a href=https://hegde95.github.io/>Shashank Hegde</a></span>
<span class=mr-2><a href=https://robotics.usc.edu/resl/people/1/>Dr. Gaurav Sukhatme</a></span></div></div><div class=card-body><p>We leverage graph hyper networks to learn graph hyper policies trained with off-policy reinforcement learning resulting in networks that are two orders of magnitude smaller than commonly used networks yet encode policies comparable to those encoded by much larger networks trained on the same task.</p></div><div class=card-footer><div class=tags><span class="btn badge btn-info ml-1 p-2">reinforcement learning</span>
<span class="btn badge btn-info ml-1 p-2">robotics</span></div><div class=details-btn><a class="btn btn-outline-info ml-1 pl-2 mb-2" href=https://sites.google.com/usc.edu/graphhyperpolicy/home target=_blank rel=noopener role=button>Details</a></div></div></div></div><div class="col-12 p-2 pub-filtr-item" data-category='pub-all,pub-reinforcement learning,pub-robotics'><div class="card mt-3"><div class=card-header><h5 class="card-title mb-0">Guided Learning of Robust Hurdling Policies with Curricular Trajectory Optimization</h5><div class=sub-title><span><a href=https://www.scr.ucla.edu/>Southern California Robotics Symposium</a></span>
<span class=ml-2>2022</span></div><div class=authors><span class=mr-2><a href=https://www.gautamsalhotra.com/>Gautam Salhotra</a></span>
<span class=mr-2><a href=https://hegde95.github.io/>Shashank Hegde</a></span>
<span class=mr-2><a href=https://sumeetbatra.github.io/>Sumeet Batra</a></span>
<span class=mr-2><a href=http://www.peter-englert.net/>Dr. Peter Englert</a></span>
<span class=mr-2><a href=https://robotics.usc.edu/resl/people/1/>Dr. Gaurav Sukhatme</a></span></div></div><div class=card-body><p>In this work, we focus on the combination of analytical and learning-based techniques to help researchers solve challenging robot locomotion problems. Specifically, we explore the combination of curricular trajectory optimization (CTO) and deep reinforcement learning (RL) for quadruped hurdling tasks.</p></div><div class=card-footer><div class=tags><span class="btn badge btn-info ml-1 p-2">reinforcement learning</span>
<span class="btn badge btn-info ml-1 p-2">robotics</span></div><div class=details-btn><a class="btn btn-outline-info ml-1 pl-2 mb-2" href=https://sites.google.com/usc.edu/cto-rl/home target=_blank rel=noopener role=button>Details</a></div></div></div></div><div class="col-12 p-2 pub-filtr-item" data-category='pub-all,pub-reinforcement learning,pub-signal processing'><div class="card mt-3"><div class=card-header><h5 class="card-title mb-0">Agents that Listen, High-Throughput Reinforcement Learning with Multiple Sensory Systems</h5><div class=sub-title><span><a href=https://ieee-cog.org/2021/>IEEE Conference on Games</a></span>
<span class=ml-2>2021</span></div><div class=authors><span class=mr-2><a href=https://hegde95.github.io/>Shashank Hegde</a></span>
<span class=mr-2><a href=https://www.microsoft.com/en-us/research/people/t-anssik/>Dr. Anssi Kanervisto</a></span>
<span class=mr-2><a href=https://alex-petrenko.github.io/>Aleksie Petrenko</a></span></div></div><div class=card-body><p>We introduce a new version of VizDoom simulator to create a highly efficient learning environment that provides raw audio observations. We study the performance of different model architectures in a series of tasks that require the agent to recognize sounds and execute instructions given in natural language. Finally, we train our agent to play the full game of Doom and find that it can consistently defeat a traditional vision-based adversary.</p></div><div class=card-footer><div class=tags><span class="btn badge btn-info ml-1 p-2">reinforcement learning</span>
<span class="btn badge btn-info ml-1 p-2">signal processing</span></div><div class=details-btn><a class="btn btn-outline-info ml-1 pl-2 mb-2" href=https://sites.google.com/view/sound-rl target=_blank rel=noopener role=button>Details</a></div></div></div></div><div class="col-12 p-2 pub-filtr-item" data-category='pub-all,pub-reinforcement learning'><div class="card mt-3"><div class=card-header><h5 class="card-title mb-0">Randomized Policy Learning for Continuous State and Action MDPs</h5><div class=sub-title><span><a href>Arxiv</a></span>
<span class=ml-2>2020</span></div><div class=authors><span class=mr-2><a href=https://www.microsoft.com/en-us/research/people/hitshar/>Dr. Hiteshi Sharma</a></span>
<span class=mr-2><a href=https://hegde95.github.io/>Shashank Hegde</a></span>
<span class=mr-2><a href=https://www.rahuljain.net/>Dr. Rahul Jain</a></span></div></div><div class=card-body><p>We present RANDPOL, a generalized policy iteration algorithm for MDPs with continuous state and action spaces. Both the policy and value functions are represented with randomized networks. We also give finite time guarantees on the performance of the algorithm.</p></div><div class=card-footer><div class=tags><span class="btn badge btn-info ml-1 p-2">reinforcement learning</span></div><div class=details-btn><a class="btn btn-outline-info ml-1 pl-2 mb-2" href=https://arxiv.org/pdf/2006.04331.pdf target=_blank rel=noopener role=button>Details</a></div></div></div></div><div class="col-12 p-2 pub-filtr-item" data-category='pub-all,pub-reinforcement learning,pub-finance'><div class="card mt-3"><div class=card-header><h5 class="card-title mb-0">Risk aware portfolio construction using deep deterministic policy gradients</h5><div class=sub-title><span><a href>IEEE Symposium Series on Computational Intelligence (SSCI)</a></span>
<span class=ml-2>2018</span></div><div class=authors><span class=mr-2><a href=https://hegde95.github.io/>Shashank Hegde</a></span>
<span class=mr-2><a href>Vishal Kumar</a></span>
<span class=mr-2><a href>Dr. Atul Singh</a></span></div></div><div class=card-body><p>This paper evaluates the use of DDPG to solve the problem of risk aware portfolio construction. Simulations are done on a portfolio of twenty stocks and the use of both Rate of Return and Sortino ratio as a measure of portfolio performance are evaluated. Results are presented that demonstrate the effectiveness of DDPG for risk aware portfolio construction.</p></div><div class=card-footer><div class=tags><span class="btn badge btn-info ml-1 p-2">reinforcement learning</span>
<span class="btn badge btn-info ml-1 p-2">finance</span></div><div class=details-btn><a class="btn btn-outline-info ml-1 pl-2 mb-2" href=https://ieeexplore.ieee.org/abstract/document/8628791 target=_blank rel=noopener role=button>Details</a></div></div></div></div></div></div></div></div><div class="container-fluid section-holder d-flex bg-secondary"><div class="container-fluid anchor pb-5 projects-section" id=projects><h1 class=text-center><span id=projects></span>Projects</h1><div class="container ml-auto text-center"><div class="btn-group flex-wrap" role=group id=project-filter-buttons><button type=button class="btn btn-dark project-filtr-control" data-filter=all>
All</button>
<button type=button class="btn btn-dark project-filtr-control" data-filter="autonomous vehicles">
Autonomous Vehicles</button>
<button type=button class="btn btn-dark project-filtr-control" data-filter="machine learning">
Machine Learning</button>
<button type=button class="btn btn-dark project-filtr-control" data-filter="deep reinforcement learning">
Deep Reinforcement Learning</button>
<button type=button class="btn btn-dark project-filtr-control" data-filter="deep learning">
Deep Learning</button>
<button type=button class="btn btn-dark project-filtr-control" data-filter="signal processing">
Signal Processing</button></div></div><div class="container filtr-projects"><div class=row id=project-card-holder><div class="col-sm-12 col-md-6 col-lg-4 p-2 filtr-item" data-category='all, machine learning'><div class="card mt-1"><div class=card><a class=card-header href=javascript:void(0)><div><div class=d-flex><h5 class="card-title mb-0">Automatic paper tagging</h5></div><div class=sub-title><span>Individual Researcher</span>
<span>September 2023 - October 2023</span></div></div></a><div class="card-body text-justify pt-1 pb-1"><p>Apply BERT sentence transformer to encode abstracts of hundreds of papers, and then find cosine similarity of the encoding with that of topic definitions to rank and tag them</p><div class=project-card-footer><div class=project-tags-holder><span class="badge btn-info">machine learning</span></div><div class=project-btn-holder></div></div></div></div></div></div><div class="col-sm-12 col-md-6 col-lg-4 p-2 filtr-item" data-category='all, autonomous vehicles'><div class="card mt-1"><div class=card><a class=card-header href=javascript:void(0)><div><div class=d-flex><h5 class="card-title mb-0">Autonomous Vehicle Navigation</h5></div><div class=sub-title><span>Team member</span>
<span>August 2019 - May 2021</span></div></div></a><div class="card-body text-justify pt-1 pb-1"><p>As a part of the Autonomous Vehicle lab, I worked on navigation, path planning and simulation of an autonomous car to take part in IGVC 2021. I used Gazebo to build an accurate simulation of the track, and implement path finding algorithms such as A star.</p><div class=project-card-footer><div class=project-tags-holder><span class="badge btn-info">autonomous vehicles</span></div><div class=project-btn-holder></div></div></div></div></div></div><div class="col-sm-12 col-md-6 col-lg-4 p-2 filtr-item" data-category='all, machine learning,deep reinforcement learning'><div class="card mt-1"><div class=card><a class=card-header href=https://hegde95.github.io/Deep_Reinforcement_Learning.pdf target=_blank rel=noopener><div><div class=d-flex><h5 class="card-title mb-0">Competetive and Co-operative Multi Agent Reinforcement Learning</h5></div><div class=sub-title><span>Individual Researcher</span>
<span>Jun 2020 - August 2020</span></div></div></a><div class="card-body text-justify pt-1 pb-1"><p>As a part of my directed research with the Hardware Accelerated Learning group, I’m experimented with various multi agent reinforcement learning algorithms. The goal of this project is to understand the state of the art RL algorithms that work well in both competitive and cooperative environments.</p><div class=project-card-footer><div class=project-tags-holder><span class="badge btn-info">machine learning</span>
<span class="badge btn-info">deep reinforcement learning</span></div><div class=project-btn-holder><span><a class="btn btn-outline-info btn-sm" href=https://hegde95.github.io/Deep_Reinforcement_Learning.pdf target=#>Details</a></span></div></div></div></div></div></div><div class="col-sm-12 col-md-6 col-lg-4 p-2 filtr-item" data-category='all, autonomous vehicles,deep reinforcement learning'><div class="card mt-1"><div class=card><a class=card-header href=https://github.com/csci-599-applied-ml-for-games/Torque-Transfer- target=_blank rel=noopener><div><div class=d-flex><h5 class="card-title mb-0">Torque Transfer</h5></div><div class=sub-title><span>Team Lead</span>
<span>August 2020 - December 2020</span></div></div></a><div class="card-body text-justify pt-1 pb-1"><p>Use reinforcement learning and transfer learning to create robust AI agents. The AI agent should generalize to a variety of open world self driving simulations. After training an AI for a self driving car simulation using Imitation learning and reinforcement learning, the learnt policy was used as a pre trained network for an AI agent in another self driving simulation. The pretrained model showed faster learning in the new simulation.</p><div class=project-card-footer><div class=project-tags-holder><span class="badge btn-info">autonomous vehicles</span>
<span class="badge btn-info">deep reinforcement learning</span></div><div class=project-btn-holder><a class="github-button project-btn d-none" href=https://github.com/csci-599-applied-ml-for-games/Torque-Transfer- data-icon=octicon-standard data-show-count=true aria-label="Star Torque Transfer">Star</a></div></div></div></div></div></div><div class="col-sm-12 col-md-6 col-lg-4 p-2 filtr-item" data-category='all, deep learning,signal processing'><div class="card mt-1"><div class=card><a class=card-header href=https://github.com/csci-599-applied-ml-for-games/Torque-Transfer- target=_blank rel=noopener><div><div class=d-flex><h5 class="card-title mb-0">Emotion Transfer on speech using spectrogram images</h5></div><div class=sub-title><span>Team Lead</span>
<span>August 2020 - December 2020</span></div></div></a><div class="card-body text-justify pt-1 pb-1"><p>Use a conditional Generative Adversarial Neural Network to generate images on spectrograms of speech signals. By using cycle GANs we use style transfer on spectrograms of speech signals to embed emotion in them. The generated spectrogram is reconstructed back to speech using the Griffin-Lim algorithm.</p><div class=project-card-footer><div class=project-tags-holder><span class="badge btn-info">deep learning</span>
<span class="badge btn-info">signal processing</span></div><div class=project-btn-holder><a class="github-button project-btn d-none" href=https://github.com/csci-599-applied-ml-for-games/Torque-Transfer- data-icon=octicon-standard data-show-count=true aria-label="Star Emotion Transfer on speech using spectrogram images">Star</a></div></div></div></div></div></div><div class="col-sm-12 col-md-6 col-lg-4 p-2 filtr-item" data-category='all, deep learning'><div class="card mt-1"><div class=card><a class=card-header href=https://github.com/hegde95/Keras-Models target=_blank rel=noopener><div><div class=d-flex><h5 class="card-title mb-0">Fashion compatibility prediction</h5></div><div class=sub-title><span>Team Lead</span>
<span>Jan 2020 - May 2020</span></div></div></a><div class="card-body text-justify pt-1 pb-1"><p>Use a Siamese Convolutional Neural Network to classify if two fashion objects are compatible with each other. Then using the pair-wise similarity scores predicted to see if an outfit is compatible. To do this Google Tensorflow 2.0 was used and the models were trained on AWS p3.2xlarge instances (Tesla V100 GPUs).</p><div class=project-card-footer><div class=project-tags-holder><span class="badge btn-info">deep learning</span></div><div class=project-btn-holder><a class="github-button project-btn d-none" href=https://github.com/hegde95/Keras-Models data-icon=octicon-standard data-show-count=true aria-label="Star Fashion compatibility prediction">Star</a></div></div></div></div></div></div><div class="col-sm-12 col-md-6 col-lg-4 p-2 filtr-item" data-category='all, deep learning'><div class="card mt-1"><div class=card><a class=card-header href=https://github.com/hegde95/Spoken_language_classifier target=_blank rel=noopener><div><div class=d-flex><h5 class="card-title mb-0">Spoken Language classifier</h5></div><div class=sub-title><span>Individual Researcher</span>
<span>Jan 2020 - May 2020</span></div></div></a><div class="card-body text-justify pt-1 pb-1"><p>Implement a Gated Recurrent Unit based Neural Network to classify the extracted MFCC features from speech audio. A streaming model classifies the language being spoken in real time. Using this streaming model, we could analyse the probability of miss-classification at every instant of speech.</p><div class=project-card-footer><div class=project-tags-holder><span class="badge btn-info">deep learning</span></div><div class=project-btn-holder><a class="github-button project-btn d-none" href=https://github.com/hegde95/Spoken_language_classifier data-icon=octicon-standard data-show-count=true aria-label="Star Spoken Language classifier">Star</a></div></div></div></div></div></div><div class="col-sm-12 col-md-6 col-lg-4 p-2 filtr-item" data-category='all, machine learning,signal processing'><div class="card mt-1"><div class=card><a class=card-header href=https://hegde95.github.io/ProjectThesis.pdf target=_blank rel=noopener><div><div class=d-flex><h5 class="card-title mb-0">Prosthetic Voice (Thesis)</h5></div><div class=sub-title><span>Team member</span>
<span>August 2016 - May 2017</span></div></div></a><div class="card-body text-justify pt-1 pb-1"><p>Undergraduate Thesis, sEMG signal controlled speech production aid for speech challenged individuals using Machine Learning. The signals were collected, filtered, pre-processed and then fed to a classifier that would predict the hand action performed. The action would then be translated to speech.</p><div class=project-card-footer><div class=project-tags-holder><span class="badge btn-info">machine learning</span>
<span class="badge btn-info">signal processing</span></div><div class=project-btn-holder><span><a class="btn btn-outline-info btn-sm" href=https://hegde95.github.io/ProjectThesis.pdf target=#>Details</a></span></div></div></div></div></div></div><div class="col-sm-12 col-md-6 col-lg-4 p-2 filtr-item" data-category='all, machine learning,signal processing'><div class="card mt-1"><div class=card><a class=card-header href=https://hegde95.github.io/EmotionRecognition.pdf target=_blank rel=noopener><div><div class=d-flex><h5 class="card-title mb-0">Emotion Detection</h5></div><div class=sub-title><span>Team member</span>
<span>August 2015 - December 2015</span></div></div></a><div class="card-body text-justify pt-1 pb-1"><p>I was part of a three member team that built a Machine Learning driven emotion detector using variations in speech signals. Using MFCC feature extraction and PCA on other features, we built a classifier.</p><div class=project-card-footer><div class=project-tags-holder><span class="badge btn-info">machine learning</span>
<span class="badge btn-info">signal processing</span></div><div class=project-btn-holder><span><a class="btn btn-outline-info btn-sm" href=https://hegde95.github.io/EmotionRecognition.pdf target=#>Details</a></span></div></div></div></div></div></div></div></div></div></div><div class="container-fluid section-holder d-flex bg-primary"><div class="container-fluid anchor pb-5 skills-section"><h1 class=text-center><span id=skills></span>Skills</h1><div class="container d-flex-block"><div class=row id=primary-skills><div class="col-xs-12 col-sm-6 col-lg-4 pt-2"><a class=text-decoration-none href=https://www.python.org/ title=Python target=_blank rel=noopener><div class=card><div class="card-head d-flex"><img class=card-img-xs src=/images/sections/skills/python_hu318d7285cf29a1ebba7e9fe511190426_9955_24x24_fit_box_3.png alt=Python><h5 class=card-title>Python</h5></div><div class=card-body><p class=card-text>Having written over tens of thousand of lines of code, I am capable of writing efficient and fast python code.</p></div></div></a></div><div class="col-xs-12 col-sm-6 col-lg-4 pt-2"><a class=text-decoration-none><div class=card><div class="card-head d-flex"><img class=card-img-xs src=/images/sections/skills/cloud_hu7018b904f8bff0d4527e1c31c6d17334_6540_24x24_fit_box_3.png alt="Cloud Computing"><h5 class=card-title>Cloud Computing</h5></div><div class=card-body><p class=card-text>Worked with most of the major clouds such as GCP, AWS, Azure etc.</p></div></div></a></div><div class="col-xs-12 col-sm-6 col-lg-4 pt-2"><a class=text-decoration-none href=https://pytorch.org/ title=Pytorch target=_blank rel=noopener><div class=card><div class="card-head d-flex"><img class=card-img-xs src=/images/sections/skills/pytorch_hu28b1b676938a5890339f7b0d0dbe3c95_51688_24x24_fit_box_3.png alt=Pytorch><h5 class=card-title>Pytorch</h5></div><div class=card-body><p class=card-text>Worked with Pytorch for over 2 years now. I am comfortable with the Pytorch ecosystem and have written many custom modules.</p></div></div></a></div><div class="col-xs-12 col-sm-6 col-lg-4 pt-2"><a class=text-decoration-none href=https://www.mathworks.com/products/matlab.html title=Matlab target=_blank rel=noopener><div class=card><div class="card-head d-flex"><img class=card-img-xs src=/images/sections/skills/matlab_hudd00a31f89ae683575b11a2f32d63f95_98345_24x24_fit_box_3.png alt=Matlab><h5 class=card-title>Matlab</h5></div><div class=card-body><p class=card-text>Capable of writing scripts in Matlab for machine learning and signal processing tasks.</p></div></div></a></div><div class="col-xs-12 col-sm-6 col-lg-4 pt-2"><a class=text-decoration-none><div class=card><div class="card-head d-flex"><img class=card-img-xs src=/images/sections/skills/linux_huf8888e89df43f58ab32b560cb211e230_26357_24x24_fit_box_3.png alt=Linux><h5 class=card-title>Linux</h5></div><div class=card-body><p class=card-text>Using as the main operating system. Capable of writing bash/shell scripts.</p></div></div></a></div><div class="col-xs-12 col-sm-6 col-lg-4 pt-2"><a class=text-decoration-none href=https://git-scm.com/ title=Git target=_blank rel=noopener><div class=card><div class="card-head d-flex"><img class=card-img-xs src=/images/sections/skills/git_hu6c1226675924c2f2e3476a81b4d03976_10660_24x24_fit_box_3.png alt=Git><h5 class=card-title>Git</h5></div><div class=card-body><p class=card-text>Experienced with git-based development. Mostly, use Github. Also, have experience in working with GitLab.</p></div></div></a></div><div class="col-xs-12 col-sm-6 col-lg-4 pt-2"><a class=text-decoration-none><div class=card><div class="card-head d-flex"><img class=card-img-xs src=/images/sections/skills/c++_hue32fe91ddbd83e8e5585833667109ec5_57810_24x24_fit_box_3.png alt=C++><h5 class=card-title>C++</h5></div><div class=card-body><p class=card-text>Know basic C/C++ programming. Used for contest programming and problem solving.</p></div></div></a></div></div></div></div></div><div class="container-fluid section-holder d-flex bg-secondary"><div class="container-fluid anchor pb-5 education-section"><h1 class=text-center><span id=education></span>Education</h1><div class=container><table class=education-info-table><tbody><tr><td class=icon><div class=hline></div><div class=icon-holder><i class="fas fa-microscope"></i></div></td><td class=line><div></div></td><td class=details><div class="degree-info card"><div class=row><div class="col-lg-10 col-md-8"><h5><a href=# title="University of Southern California" target=_blank rel=noopener>University of Southern California</a></h5></div><div class="timeframe col-lg-2 col-md-4">2021-Present</div></div><h6>Ph.D in Electrical and Computer Engineering</h6><h6><span class=text-heading>CGPA: </span><span>3.94</span> out of <span>4</span></h6></div></td></tr><tr><td class=icon><div class=hline></div><div class=icon-holder><i class="fas fa-microscope"></i></div></td><td class=line><div></div></td><td class=details><div class="degree-info card"><div class=row><div class="col-lg-10 col-md-8"><h5><a href=# title="University of Southern California" target=_blank rel=noopener>University of Southern California</a></h5></div><div class="timeframe col-lg-2 col-md-4">2019-2021</div></div><h6>M.S. in Electrical and Computer Engineering</h6><h6><span class=text-heading>CGPA: </span><span>3.94</span> out of <span>4</span></h6></div></td></tr><tr><td class=icon><div class=hline></div><div class=icon-holder><i class="fas fa-microscope"></i></div></td><td class=line><div></div></td><td class=details><div class="degree-info card"><div class=row><div class="col-lg-10 col-md-8"><h5><a href=# title="National Institute of Technology Karnataka" target=_blank rel=noopener>National Institute of Technology Karnataka</a></h5></div><div class="timeframe col-lg-2 col-md-4">2013-2017</div></div><h6>B.Tech. in Electrical and Electronics Engineering</h6><h6><span class=text-heading>CGPA: </span><span>8.17</span> out of <span>10</span></h6></div></td></tr></tbody></table></div></div></div><div class="container-fluid section-holder d-flex bg-primary"><div class="container-fluid anchor pb-5 accomplishments-section"><h1 class=text-center><span id=accomplishments></span>Accomplishments and Service</h1><div class=container><div class=row id=acomplishment-card-holder><div class="col-md-12 col-lg-6 p-2"><div class="card mt-3"><div class=card-header><h5 class="card-title mb-0">USC Annenberg Fellow</h5><div class=sub-title><span><a href=https://www.usc.edu/ title=USC target=_blank rel=noopener>USC</a></span>
<span class=ml-2>August 2021 - July 2022</span></div></div><div class=card-body><p>Awarded a 1 year Fellowship for my PhD.</p></div><div class=card-footer></div></div></div><div class="col-md-12 col-lg-6 p-2"><div class="card mt-3"><div class=card-header><h5 class="card-title mb-0">Masters Student Honors Program</h5><div class=sub-title><span><a href=https://www.usc.edu/ title=USC target=_blank rel=noopener>USC</a></span>
<span class=ml-2>August 2019 - May 2021</span></div></div><div class=card-body><p>Certificate for outstanding academic and research achievements. <a href="https://drive.google.com/file/d/1djUmdEsNsV79VZD9PZrSuDi_g4JKgMR4/view?usp=sharing" target=_blank rel=noopener>PDF</a></p></div><div class=card-footer></div></div></div><div class="col-md-12 col-lg-6 p-2"><div class="card mt-3"><div class=card-header><h5 class="card-title mb-0">The Data Open</h5><div class=sub-title><span><a href title=Citadel target=_blank rel=noopener>Citadel</a></span>
<span class=ml-2></span></div></div><div class=card-body><p>Was a finalist in the SoCal round of the Data Open Hackathon organized by Citadel. <a href=https://hegde95.github.io/Datathon.pdf target=_blank rel=noopener>PDF</a></p></div><div class=card-footer></div></div></div><div class="col-md-12 col-lg-6 p-2"><div class="card mt-3"><div class=card-header><h5 class="card-title mb-0">Soda bottle classification contest</h5><div class=sub-title><span><a href title="Deep Congintion" target=_blank rel=noopener>Deep Congintion</a></span>
<span class=ml-2></span></div></div><div class=card-body><p>Winner of image classification contest by Deep Cognition.<a href=https://deepcognition.ai/soda-bottle-identification-challenge/ target=_blank rel=noopener>link</a></p></div><div class=card-footer></div></div></div><div class="col-md-12 col-lg-6 p-2"><div class="card mt-3"><div class=card-header><h5 class="card-title mb-0">Teaching Assistant</h5><div class=sub-title><span><a href=https://www.usc.edu/ title=USC target=_blank rel=noopener>USC</a></span>
<span class=ml-2>August 2022 - Decemeber 2022</span></div></div><div class=card-body><p>EE541 - A Computational Introduction to Deep Learning<br>EE641 - Deep Learning Systems<br>CSCI567 - Machine Learning \</p></div><div class=card-footer></div></div></div><div class="col-md-12 col-lg-6 p-2"><div class="card mt-3"><div class=card-header><h5 class="card-title mb-0">Invited Speaker</h5><div class=sub-title><span><a href title="Sears Deep Learning Center Program" target=_blank rel=noopener>Sears Deep Learning Center Program</a></span>
<span class=ml-2></span></div></div><div class=card-body><p>Delivered a company wide talk on SOTA applied Deep Reinforcement Learning. <a href="https://docs.google.com/presentation/d/1o6Xk72dysR1NBkjC5atEnxPXqdHGRVa9/edit?usp=sharing&amp;ouid=102978441719964927294&amp;rtpof=true&amp;sd=true" target=_blank rel=noopener>pdf</a></p></div><div class=card-footer></div></div></div><div class="col-md-12 col-lg-6 p-2"><div class="card mt-3"><div class=card-header><h5 class="card-title mb-0">Guest Lecture</h5><div class=sub-title><span><a href title="For the graduate machine learning course" target=_blank rel=noopener>For the graduate machine learning course</a></span>
<span class=ml-2></span></div></div><div class=card-body><p>Presented a talk on Generative models for robotics</p></div><div class=card-footer></div></div></div></div></div></div></div><footer id=footer class="container-fluid text-center align-content-center footer pb-2"><div class="container pt-5"><div class="row text-left"><div class="col-md-4 col-sm-12"><h5>Navigation</h5><ul><li class=nav-item><a class=smooth-scroll href=https://hegde95.github.io#about>About</a></li><li class=nav-item><a class=smooth-scroll href=https://hegde95.github.io#experiences>Experiences</a></li><li class=nav-item><a class=smooth-scroll href=https://hegde95.github.io#publications>Select Publications</a></li><li class=nav-item><a class=smooth-scroll href=https://hegde95.github.io#projects>Projects</a></li><li class=nav-item><a class=smooth-scroll href=https://hegde95.github.io#skills>Skills</a></li><li class=nav-item><a class=smooth-scroll href=https://hegde95.github.io#education>Education</a></li><li class=nav-item><a class=smooth-scroll href=https://hegde95.github.io#accomplishments>Accomplishments and Service</a></li></ul></div><div class="col-md-4 col-sm-12"><h5>Contact me:</h5><ul><li><a href=mailto:kshegde6@gmail.com target=_blank rel=noopener><span><i class="fas fa-envelope"></i></span> <span>kshegde6@gmail.com</span></a></li><li><a href=https://github.com/hegde95 target=_blank rel=noopener><span><i class="fab fa-github"></i></span> <span>hegde95</span></a></li><li><a href=https://www.linkedin.com/in/karkala-shashank-hegde target=_blank rel=noopener><span><i class="fab fa-linkedin"></i></span> <span>Shashank Hegde</span></a></li></ul></div></div></div><hr><div class=container><div class="row text-left"><div class=col-md-4><a id=theme href=https://github.com/hugo-toha/toha target=_blank rel=noopener><img src=/images/theme-logo_hu8376fd15465fef26ffe66b6bcf0ca686_13669_32x0_resize_box_3.png alt="Toha Theme Logo">
Toha</a></div><div class="col-md-4 text-center">© 2020 Copyright.</div><div class="col-md-4 text-right"><a id=hugo href=https://gohugo.io/ target=_blank rel=noopener>Powered by
<img src=/images/hugo-logo.svg alt="Hugo Logo" height=18></a></div></div></div></footer><script src=/application.ecb9a78190558f68ecbaeb8f10a0cecbb1a52fa5c7472805abbbadc0c4d29030.js integrity="sha256-7LmngZBVj2jsuuuPEKDOy7GlL6XHRygFq7utwMTSkDA=" defer></script></body></html>